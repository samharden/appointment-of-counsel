
{% extends "base0.html" %}

{% block content %}





<h3 class="title-border" style="text-align: center;">The Defendant and the Algorithm</h3>
<center>
<img href="" src="https://res.cloudinary.com/hjbqakjln/image/upload/v1489462862/33116625231_feec23b912_adaila.jpg" alt="image description" style="width:304px;height:228px;">
</center>
<p class="landing-section-heading" style="text-align: justify;">
Should we put algorithms in charge of our criminal justice system? Would an impartial
AI make better decisions than our human and fallible judges when it comes to
deciding legal issues?
</p>
One of the news stories making the rounds recently claims that a computer algorithm
would be a significant improvement over a judge's discretion when deciding which
defendants were eligible for pre-trial release, and which ones should stay in jail
awaiting trial. From the article in the <a href="https://www.technologyreview.com/s/603763/how-to-upgrade-judges-with-machine-learning/">MIT Technology Review</a>:
</p>
<blockquote style="text-align: justify;">
  In a new study from the National Bureau of Economic Research, economists and
  computer scientists trained an algorithm to predict whether defendants were a
  flight risk from their rap sheet and court records using data from hundreds of
  thousands of cases in New York City. When tested on over a hundred thousand more
  cases that it hadnâ€™t seen before, the algorithm proved better at predicting what
  defendants will do after release than judges.
</blockquote>
<p class="landing-section-heading" style="text-align: justify;">
Yet another article talks about how <a href="https://qz.com/920196/criminal-court-judges-in-new-jersey-now-use-algorithms-to-guide-decisions-on-bail/">
judges in New Jersey are using an algorithm</a> to guide their decisions on
granting defendants pre-trial release without bail.
</p>
<p class="landing-section-heading" style="text-align: justify;">
The promise of AI: that a machine can suddenly remove the implicit bias of judges
and make the justice system more just. Remove the decision making power from humans,
put the machine in charge. Now salivating over the prospect of the terms "AI" and
"machine learning" the techno-elite are aiming their disruptor beams at the
criminal justice system.
</p>
<p class="landing-section-heading" style="text-align: justify;">
This isn't to say the criminal justice system is operating well. Quite the contrary.
Judges do have implicit bias. Minorities are policed and convicted at a much higher
rate than non-minorities.
</p>
<p class="landing-section-heading" style="text-align: justify;">
The idea of algorithms taking decision making out of judges' hands reminds of a
similar scheme from the 1980's - when states and the federal government began
enacting mandatory minimum sentences. Judges, so the argument went, had too
much discretion and were letting dangerous criminals go with light sentences
because their emotions were getting in the way. Mandatory minimums were
supposed to standardize punishment for crimes, reduce recidivism, and deter
people from crime simply by being on the books. This <a href="http://famm.org/wp-content/uploads/2017/03/Journal_Spr2017_PoorResultsGoodIntentions.pdf">has not worked as planned</a>.
Their <a href="http://www.fjc.gov/public/pdf.nsf/lookup/conmanmin.pdf/$file/conmanmin.pdf">list of ills goes on</a>. And on. <a href="http://www.rollingstone.com/politics/news/the-nations-shame-the-injustice-of-mandatory-minimums-20141007">And on</a>.
</p>
<p class="landing-section-heading" style="text-align: justify;">
It also reminds me of a scene from the movie Brazil, where a bug gets caught in a
mechanical typewriter, <a href = "http://gizmodo.com/welcome-to-brazil-where-a-computer-bug-condemns-a-man-1659912414">
  causes a typo and thereby the death of someone whose name
is remarkably close to that of an alleged terrorist</a>.
</p>
<p class="landing-section-heading" style="text-align: justify;">
Perhaps our betters would proceed with a modicum of caution then, when considering
the wonders of their new and improved standardized justice algorithm.
</p>
<p class="landing-section-heading" style="text-align: justify;">
But there are more than philosphical problems with implementing algorithmic justice
at the court level. Courts are strapped for funding. The computer systems courts use,
even when up-to-date, are <a href="https://arstechnica.com/tech-policy/2016/12/court-software-glitches-result-in-erroneous-arrests-defense-lawyers-say/">error prone and faulty</a>.
Some of those errors even mean warrants are issued for the wrong people, people
<a href="https://arstechnica.com/tech-policy/2017/02/inadequate-court-software-still-gets-people-wrongly-arrested-lawyers-say/">stay jailed longer than they should</a>,
and court staff and attorneys must work overtime to prevent the machine-created
errors from causing more injustice.
</p>
<p class="landing-section-heading" style="text-align: justify;">
Changing to an algoritm-driven justice system will mean adding new layers of
complexity onto an already burdened system. Algorithms, after all, are only as
good as the data that gets fed to them. In many jurisdictions the Odyssey system
(with the problems mentioned above) handles all of the court's data both internally
and externally. Add to that the problem of different jurisdictions and agencies
having their data in different silos, and our true and just algorithm is nothing more than
a computer program operating on incomplete and erroneous data sets.
</p>
<p class="landing-section-heading" style="text-align: justify;">
Computer algorithms are not without their own inherent biases. A study by Pro-Publica
found that a <a href="https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing">computer program used to determine a defendant's risk of re-offending
was heavily biased against black people</a>. Consider too the problem of who (or what)
is the actual owner of the algorithm once it's in place. Does the actual computer code
fall under public records laws so that it can be examined for bias? Or does it, like
the <a href="https://reason.com/blog/2017/02/16/law-enforcement-continue-to-dodge-attemp/print">Stingray cell phone monitoring device</a>, fall under some kind of non-disclosure agreement
that encourages the court to keep it a closely-guarded secret? Would the machine's inherent
bias even be up for debate?
</p>
<p class="landing-section-heading" style="text-align: justify;">
There is room in criminal justice for data analysis and algorithmic guidance. This site,
after all, is built on the idea that algorithmic data analysis can help people
facing the court system. But when it's the state imposing its might through a faceless
algorithm we have to take great care. The rules of disrpution - move fast and break
things - shouldn't apply when we're talking about someone's liberty.
</p>
<p class="landing-section-heading" style="text-align: justify;">

</p>
<a href="https://creativecommons.org/licenses/by-nc-sa/2.0/">Photo License</a>

{% endblock %}
